# AI Services - Gemini Integration

Este m√≥dulo proporciona integraci√≥n con Google Gemini AI para el sistema de chat nutricional context-aware.

## Configuraci√≥n

### 1. Obtener API Key de Gemini

1. Ve a [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Inicia sesi√≥n con tu cuenta de Google
3. Crea una nueva API key
4. Copia la API key generada

### 2. Configurar Variables de Entorno

Agrega la siguiente variable a tu archivo `.env` en el directorio `backend`:

```bash
# AI Services
GEMINI_API_KEY=tu_api_key_aqui
DEFAULT_AI_MODEL=gemini-pro
```

**Opcional**: Si planeas usar Claude en el futuro:
```bash
ANTHROPIC_API_KEY=tu_api_key_de_claude
```

### 3. Reiniciar el Servidor

Despu√©s de agregar la API key, reinicia el servidor backend:

```bash
# Desarrollo
cd backend
uvicorn main:app --reload

# Docker
docker compose restart backend
```

## Uso

### Endpoint Principal: `/api/v1/rag/chat`

```bash
POST /api/v1/rag/chat
Authorization: Bearer {token}
Content-Type: application/json

{
  "message": "¬øQu√© alimentos puedo comer si tengo diabetes?",
  "include_context": true,
  "include_search_results": true
}
```

**Respuesta**:
```json
{
  "message": "¬øQu√© alimentos puedo comer si tengo diabetes?",
  "user_id": 123,
  "context_included": true,
  "search_included": true,
  "ai_response": "Como nutri√≥logo experto...",
  "model": "gemini-pro",
  "usage": {
    "prompt_tokens": 1500,
    "completion_tokens": 400,
    "total_tokens": 1900
  },
  "user_context_summary": {
    "scan_count": 45,
    "favorite_foods_count": 12
  }
}
```

## Caracter√≠sticas

### 1. Chat Context-Aware
- Acceso autom√°tico al historial de escaneos del usuario
- Incluye productos favoritos y estad√≠sticas
- Respuestas personalizadas basadas en el perfil

### 2. An√°lisis Nutricional
```python
from backend.services.ai.gemini_service import GeminiService

gemini = GeminiService()
result = await gemini.nutritional_analysis(product_data)
```

### 3. Sugerencias de Planes de Comida
```python
result = await gemini.meal_plan_suggestions(
    user_profile={
        "edad": 35,
        "peso_kg": 75,
        "altura_cm": 170,
        "objetivo_nutricional": "bajar de peso"
    }
)
```

## Prompts del Sistema

### Contexto Nutricional Mexicano

El servicio est√° optimizado para:
- **NOM-051-SCFI/SSA1-2010**: Etiquetado frontal mexicano
- **SMAE**: Sistema Mexicano de Alimentos Equivalentes
- **Sellos de Advertencia**: Explicaci√≥n autom√°tica
- **Alimentos Tradicionales**: Contexto cultural mexicano

### Sellos de Advertencia

El sistema explica autom√°ticamente:
- üî¥ **Exceso calor√≠as**: >275 kcal/100g
- üî¥ **Exceso az√∫cares**: >10g/100g
- üî¥ **Exceso grasas saturadas**: >4g/100g
- üî¥ **Exceso grasas trans**: >0.5g/100g
- üî¥ **Exceso sodio**: >300mg/100g

## Seguridad

### Filtros de Contenido

El servicio incluye filtros de seguridad para:
- ‚úÖ Hate speech: BLOCK_MEDIUM_AND_ABOVE
- ‚úÖ Dangerous content: BLOCK_MEDIUM_AND_ABOVE
- ‚úÖ Sexually explicit: BLOCK_MEDIUM_AND_ABOVE
- ‚úÖ Harassment: BLOCK_MEDIUM_AND_ABOVE

### Limitaciones √âticas

La IA **NUNCA**:
- ‚ùå Diagnostica enfermedades
- ‚ùå Proporciona tratamientos m√©dicos
- ‚ùå Reemplaza consultas profesionales
- ‚ùå Juzga las decisiones alimentarias

La IA **SIEMPRE**:
- ‚úÖ Refiere a profesionales de salud cuando es necesario
- ‚úÖ Basa respuestas en evidencia cient√≠fica
- ‚úÖ Es emp√°tica y motivadora
- ‚úÖ Respeta el contexto cultural

## Configuraci√≥n Avanzada

### Ajustar Par√°metros de Generaci√≥n

En `gemini_service.py`, m√©todo `_get_generation_config()`:

```python
{
    "temperature": 0.7,      # Creatividad (0.0-1.0)
    "top_p": 0.95,           # Nucleus sampling
    "top_k": 40,             # Top-k sampling
    "max_output_tokens": 2048 # Tokens m√°ximos
}
```

### Cambiar Modelo

Modelos disponibles:
- `gemini-pro` (recomendado)
- `gemini-pro-vision` (para im√°genes)
- `gemini-ultra` (pr√≥ximamente)

Cambiar en `.env`:
```bash
DEFAULT_AI_MODEL=gemini-pro-vision
```

## Monitoreo y Logs

El servicio genera logs autom√°ticos:

```python
logger.info(f"Sending request to Gemini API (message length: {len(user_message)})")
logger.info(f"Gemini response received (length: {len(response.text)})")
logger.error(f"Error calling Gemini API: {str(e)}", exc_info=True)
```

### Verificar Estado

```bash
GET /api/v1/rag/health
```

Respuesta:
```json
{
  "status": "healthy",
  "service": "RAG (Retrieval Augmented Generation)",
  "version": "1.0.0",
  "endpoints": {
    "chat": ["/rag/chat"],
    "search": [...],
    "context": [...]
  }
}
```

## Costos y L√≠mites

### Google Gemini Pro

- **Free tier**: 60 requests/minute
- **Paid tier**: Mayor throughput
- **Costo**: $0.00025/1K tokens (prompt) + $0.0005/1K tokens (completion)

### Optimizaci√≥n de Costos

1. **Cache de Contexto**: Reutiliza contexto cuando sea posible
2. **L√≠mite de Tokens**: Configurado a 2048 tokens m√°ximo
3. **Contexto Selectivo**: Usa `include_context=false` si no necesitas historial

## Troubleshooting

### Error: "Gemini API key not configured"

**Soluci√≥n**: Verifica que `GEMINI_API_KEY` est√© en tu archivo `.env`

```bash
# Verificar en Docker
docker compose exec backend env | grep GEMINI_API_KEY

# Verificar localmente
echo $GEMINI_API_KEY
```

### Error: "Response blocked by safety filters"

**Soluci√≥n**: El contenido fue bloqueado por filtros de seguridad. Revisa:
- El mensaje del usuario no contiene contenido inapropiado
- El contexto proporcionado es relevante al tema nutricional

### Error: "Rate limit exceeded"

**Soluci√≥n**:
- Espera 1 minuto y reintentar
- Considera upgrade a plan pagado
- Implementa cache/retry logic

## Pr√≥ximos Pasos

- [ ] Implementar frontend de chat
- [ ] Agregar soporte para streaming responses
- [ ] Implementar cache de respuestas
- [ ] Agregar soporte para Claude AI
- [ ] Implementar analytics de uso

## Recursos

- [Gemini API Documentation](https://ai.google.dev/docs)
- [Google AI Studio](https://makersuite.google.com/)
- [NOM-051 Information](https://www.gob.mx/cofepris/documentos/nom-051)
- [SMAE Documentation](https://www.smae.nutricion.org/)
